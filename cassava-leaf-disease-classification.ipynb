{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Loading Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:37.543543Z","iopub.status.busy":"2022-05-18T18:33:37.542500Z","iopub.status.idle":"2022-05-18T18:33:43.964865Z","shell.execute_reply":"2022-05-18T18:33:43.964104Z","shell.execute_reply.started":"2022-05-18T18:33:37.543416Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import datetime\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import tensorflow as tf\n","from tensorflow.keras import models, layers\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.optimizers import Adam\n","\n","# ignoring warnings\n","import warnings\n","warnings.simplefilter(\"ignore\")\n","\n","import os, cv2, json\n","from PIL import Image"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:43.968175Z","iopub.status.busy":"2022-05-18T18:33:43.967928Z","iopub.status.idle":"2022-05-18T18:33:43.978118Z","shell.execute_reply":"2022-05-18T18:33:43.977459Z","shell.execute_reply.started":"2022-05-18T18:33:43.968141Z"},"trusted":true},"outputs":[],"source":["WORK_DIR = '../input/cassava-leaf-disease-classification'\n","os.listdir(WORK_DIR)"]},{"cell_type":"markdown","metadata":{},"source":["# Looking at the data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:43.980322Z","iopub.status.busy":"2022-05-18T18:33:43.979758Z","iopub.status.idle":"2022-05-18T18:33:44.527991Z","shell.execute_reply":"2022-05-18T18:33:44.527223Z","shell.execute_reply.started":"2022-05-18T18:33:43.980284Z"},"trusted":true},"outputs":[],"source":["print('Train images: %d' %len(os.listdir(\n","    os.path.join(WORK_DIR, \"train_images\"))))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:44.530795Z","iopub.status.busy":"2022-05-18T18:33:44.530512Z","iopub.status.idle":"2022-05-18T18:33:44.540596Z","shell.execute_reply":"2022-05-18T18:33:44.539743Z","shell.execute_reply.started":"2022-05-18T18:33:44.530757Z"},"trusted":true},"outputs":[],"source":["with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n","    print(json.dumps(json.loads(file.read()), indent=4))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:44.542637Z","iopub.status.busy":"2022-05-18T18:33:44.542090Z","iopub.status.idle":"2022-05-18T18:33:44.581687Z","shell.execute_reply":"2022-05-18T18:33:44.581017Z","shell.execute_reply.started":"2022-05-18T18:33:44.542594Z"},"trusted":true},"outputs":[],"source":["train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\n","train_labels.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Plotting the count of each label"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:44.583352Z","iopub.status.busy":"2022-05-18T18:33:44.582879Z","iopub.status.idle":"2022-05-18T18:33:44.812396Z","shell.execute_reply":"2022-05-18T18:33:44.811736Z","shell.execute_reply.started":"2022-05-18T18:33:44.583315Z"},"trusted":true},"outputs":[],"source":["sns.set_style(\"whitegrid\")\n","fig, ax = plt.subplots(figsize = (6, 4))\n","\n","for i in ['top', 'right', 'left']:\n","    ax.spines[i].set_visible(False)\n","ax.spines['bottom'].set_color('black')\n","\n","sns.countplot(train_labels.label, edgecolor = 'black',\n","              palette = reversed(sns.color_palette(\"viridis\", 5)))\n","plt.xlabel('Classes', fontfamily = 'serif', size = 15)\n","plt.ylabel('Count', fontfamily = 'serif', size = 15)\n","plt.xticks(fontfamily = 'serif', size = 12)\n","plt.yticks(fontfamily = 'serif', size = 12)\n","ax.grid(axis = 'y', linestyle = '--', alpha = 0.9)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Looking at images from each label"]},{"cell_type":"markdown","metadata":{},"source":["## Photos of class 0: Cassava Bacterial Blight (CBB)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:44.814104Z","iopub.status.busy":"2022-05-18T18:33:44.813853Z","iopub.status.idle":"2022-05-18T18:33:45.408840Z","shell.execute_reply":"2022-05-18T18:33:45.408132Z","shell.execute_reply.started":"2022-05-18T18:33:44.814060Z"},"trusted":true},"outputs":[],"source":["sample = train_labels[train_labels.label == 0].sample(3)\n","plt.figure(figsize=(15, 5))\n","for ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n","    plt.subplot(1, 3, ind + 1)\n","    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Photos of class '1': Cassava Brown Streak Disease (CBSD)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:45.409970Z","iopub.status.busy":"2022-05-18T18:33:45.409758Z","iopub.status.idle":"2022-05-18T18:33:45.984896Z","shell.execute_reply":"2022-05-18T18:33:45.983324Z","shell.execute_reply.started":"2022-05-18T18:33:45.409935Z"},"trusted":true},"outputs":[],"source":["sample = train_labels[train_labels.label == 1].sample(3)\n","plt.figure(figsize=(15, 5))\n","for ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n","    plt.subplot(1, 3, ind + 1)\n","    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Photos of class '2': Cassava Green Mottle (CGM)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:45.986969Z","iopub.status.busy":"2022-05-18T18:33:45.986503Z","iopub.status.idle":"2022-05-18T18:33:46.562125Z","shell.execute_reply":"2022-05-18T18:33:46.561535Z","shell.execute_reply.started":"2022-05-18T18:33:45.986934Z"},"trusted":true},"outputs":[],"source":["sample = train_labels[train_labels.label == 2].sample(3)\n","plt.figure(figsize=(15, 5))\n","for ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n","    plt.subplot(1, 3, ind + 1)\n","    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Photos of class '3': Cassava Mosaic Disease (CMD)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:46.564979Z","iopub.status.busy":"2022-05-18T18:33:46.564631Z","iopub.status.idle":"2022-05-18T18:33:47.116896Z","shell.execute_reply":"2022-05-18T18:33:47.115344Z","shell.execute_reply.started":"2022-05-18T18:33:46.564948Z"},"trusted":true},"outputs":[],"source":["sample = train_labels[train_labels.label == 3].sample(3)\n","plt.figure(figsize=(15, 5))\n","for ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n","    plt.subplot(1, 3, ind + 1)\n","    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Photos of class '4': Healthy"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:47.118902Z","iopub.status.busy":"2022-05-18T18:33:47.118448Z","iopub.status.idle":"2022-05-18T18:33:47.676122Z","shell.execute_reply":"2022-05-18T18:33:47.675404Z","shell.execute_reply.started":"2022-05-18T18:33:47.118867Z"},"trusted":true},"outputs":[],"source":["sample = train_labels[train_labels.label == 4].sample(3)\n","plt.figure(figsize=(15, 5))\n","for ind, (image_id, label) in enumerate(zip(sample.image_id, sample.label)):\n","    plt.subplot(1, 3, ind + 1)\n","    img = cv2.imread(os.path.join(WORK_DIR, \"train_images\", image_id))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Preparation for Modeling"]},{"cell_type":"markdown","metadata":{},"source":["## Main Parameters"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:47.678097Z","iopub.status.busy":"2022-05-18T18:33:47.677351Z","iopub.status.idle":"2022-05-18T18:33:47.682818Z","shell.execute_reply":"2022-05-18T18:33:47.682072Z","shell.execute_reply.started":"2022-05-18T18:33:47.678049Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 32\n","STEPS_PER_EPOCH = len(train_labels)*0.8 / BATCH_SIZE\n","VALIDATION_STEPS = len(train_labels)*0.2 / BATCH_SIZE\n","EPOCHS = 4\n","TARGET_SIZE = 512 "]},{"cell_type":"markdown","metadata":{},"source":["## Image Data Generator"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:33:47.684618Z","iopub.status.busy":"2022-05-18T18:33:47.684313Z","iopub.status.idle":"2022-05-18T18:34:38.098840Z","shell.execute_reply":"2022-05-18T18:34:38.098125Z","shell.execute_reply.started":"2022-05-18T18:33:47.684541Z"},"trusted":true},"outputs":[],"source":["train_labels.label = train_labels.label.astype('str')\n","\n","train_datagen = ImageDataGenerator(validation_split = 0.2,\n","                                     preprocessing_function = None,\n","                                     rotation_range = 45,\n","                                     zoom_range = 0.2,\n","                                     horizontal_flip = True,\n","                                     vertical_flip = True,\n","                                     fill_mode = 'nearest',\n","                                     shear_range = 0.1,\n","                                     height_shift_range = 0.1,\n","                                     width_shift_range = 0.1)\n","\n","train_generator = train_datagen.flow_from_dataframe(train_labels,\n","                         directory = os.path.join(WORK_DIR, \"train_images\"),\n","                         subset = \"training\",\n","                         x_col = \"image_id\",\n","                         y_col = \"label\",\n","                         target_size = (TARGET_SIZE, TARGET_SIZE),\n","                         batch_size = BATCH_SIZE,\n","                         class_mode = \"sparse\")\n","\n","\n","validation_datagen = ImageDataGenerator(validation_split = 0.2)\n","\n","validation_generator = validation_datagen.flow_from_dataframe(train_labels,\n","                         directory = os.path.join(WORK_DIR, \"train_images\"),\n","                         subset = \"validation\",\n","                         x_col = \"image_id\",\n","                         y_col = \"label\",\n","                         target_size = (TARGET_SIZE, TARGET_SIZE),\n","                         batch_size = BATCH_SIZE,\n","                         class_mode = \"sparse\")"]},{"cell_type":"markdown","metadata":{},"source":["# Data Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["## Random Photo Before Augmentation"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:34:38.100336Z","iopub.status.busy":"2022-05-18T18:34:38.100071Z","iopub.status.idle":"2022-05-18T18:34:38.329296Z","shell.execute_reply":"2022-05-18T18:34:38.328609Z","shell.execute_reply.started":"2022-05-18T18:34:38.100299Z"},"trusted":true},"outputs":[],"source":["img_path = os.path.join(WORK_DIR, \"train_images\", train_labels.image_id[20])\n","img = image.load_img(img_path, target_size = (TARGET_SIZE, TARGET_SIZE))\n","img_tensor = image.img_to_array(img)\n","img_tensor = np.expand_dims(img_tensor, axis = 0)\n","img_tensor /= 255.\n","\n","plt.imshow(img_tensor[0])\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Same Photo after augmentation"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:34:38.330955Z","iopub.status.busy":"2022-05-18T18:34:38.330608Z","iopub.status.idle":"2022-05-18T18:34:40.962156Z","shell.execute_reply":"2022-05-18T18:34:40.961363Z","shell.execute_reply.started":"2022-05-18T18:34:38.330923Z"},"trusted":true},"outputs":[],"source":["generator = train_datagen.flow_from_dataframe(train_labels.iloc[20:21],\n","                         directory = os.path.join(WORK_DIR, \"train_images\"),\n","                         x_col = \"image_id\",\n","                         y_col = \"label\",\n","                         target_size = (TARGET_SIZE, TARGET_SIZE),\n","                         batch_size = BATCH_SIZE,\n","                         class_mode = \"sparse\")\n","\n","aug_images = [generator[0][0][0]/255 for i in range(10)]\n","fig, axes = plt.subplots(2, 5, figsize = (20, 10))\n","axes = axes.flatten()\n","for img, ax in zip(aug_images, axes):\n","    ax.imshow(img)\n","    ax.axis('off')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Experimentation with different Models"]},{"cell_type":"markdown","metadata":{},"source":["# EfficientNetB0"]},{"cell_type":"markdown","metadata":{},"source":["1. 4 hidden layers : [1024,512,128,64]\n","2. used Dropout after each layer\n","3. Metrics used: Accuracy\n","4. EPOCHS = 4\n","5. TARGET_SIZE = 512\n","6. BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-05-18T18:34:40.963954Z","iopub.status.busy":"2022-05-18T18:34:40.963244Z","iopub.status.idle":"2022-05-18T18:34:40.974350Z","shell.execute_reply":"2022-05-18T18:34:40.973748Z","shell.execute_reply.started":"2022-05-18T18:34:40.963913Z"},"trusted":true},"outputs":[],"source":["def create_model():\n","    conv_base = EfficientNetB0(include_top = False, weights = 'imagenet',\n","                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n","    conv_base.trainable=False\n","    model = conv_base.output\n","    model = layers.GlobalAveragePooling2D()(model)\n","    model = layers.Dense(1024, activation = 'relu')(model)\n","    model = layers.Dropout(0.3)(model)\n","    model = layers.Dense(512, activation = 'relu')(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(128, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(64, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(5, activation = \"softmax\")(model)\n","    model = models.Model(conv_base.input, model)\n","\n","    model.compile(optimizer = Adam(lr = 0.001),\n","                  loss = \"sparse_categorical_crossentropy\",\n","                  metrics = [\"acc\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = create_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_save = ModelCheckpoint('./EffNetB0_32_512_best_weights.h5', \n","                             save_best_only = True, \n","                             save_weights_only = True,\n","                             monitor = 'val_loss', \n","                             mode = 'min', verbose = 1)\n","early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n","                           patience = 5, mode = 'min', verbose = 1,\n","                           restore_best_weights = True)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n","                              patience = 2, min_delta = 0.001, \n","                              mode = 'min', verbose = 1)\n","\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    validation_data = validation_generator,\n","    validation_steps = VALIDATION_STEPS,\n","    callbacks = [model_save, early_stop, reduce_lr]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","sns.set_style(\"white\")\n","plt.suptitle('Train history', size = 15)\n","\n","ax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\n","ax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\n","ax1.set_title(\"Training and validation acc\")\n","ax1.legend()\n","\n","ax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\n","ax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\n","ax2.set_title(\"Training and validation loss\")\n","ax2.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# ResNet50"]},{"cell_type":"markdown","metadata":{},"source":["## 1)\n","\n","1. 4 hidden layers : [1024,512,128,64]\n","2. used Dropout after each layer\n","3. Metrics used: Accuracy\n","4. EPOCHS = 4\n","5. TARGET_SIZE = 256\n","6. BATCH_SIZE = 16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_model():\n","    conv_base = ResNet50(include_top = False, weights = 'imagenet',\n","                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n","    conv_base.trainable=False\n","    model = conv_base.output\n","    model = layers.GlobalAveragePooling2D()(model)\n","    model = layers.Dense(1024, activation = 'relu')(model)\n","    model = layers.Dropout(0.3)(model)\n","    model = layers.Dense(512, activation = 'relu')(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(128, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(64, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(5, activation = \"softmax\")(model)\n","    model = models.Model(conv_base.input, model)\n","\n","    model.compile(optimizer = Adam(lr = 0.001),\n","                  loss = \"sparse_categorical_crossentropy\",\n","                  metrics = [\"acc\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = create_model()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_save = ModelCheckpoint('./ResNet50_16_256_best_weights.h5', \n","                             save_best_only = True, \n","                             save_weights_only = True,\n","                             monitor = 'val_loss', \n","                             mode = 'min', verbose = 1)\n","early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n","                           patience = 5, mode = 'min', verbose = 1,\n","                           restore_best_weights = True)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n","                              patience = 2, min_delta = 0.001, \n","                              mode = 'min', verbose = 1)\n","\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    validation_data = validation_generator,\n","    validation_steps = VALIDATION_STEPS,\n","    callbacks = [model_save, early_stop, reduce_lr]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","sns.set_style(\"white\")\n","plt.suptitle('Train history', size = 15)\n","\n","ax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\n","ax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\n","ax1.set_title(\"Training and validation acc\")\n","ax1.legend()\n","\n","ax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\n","ax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\n","ax2.set_title(\"Training and validation loss\")\n","ax2.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 2)\n","\n","1. 4 hidden layers : [1024,512,128,64]\n","2. used Dropout after each layer\n","3. Metrics used: Accuracy\n","4. EPOCHS = 3\n","5. TARGET_SIZE = 512\n","6. BATCH_SIZE = 16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_model():\n","    conv_base = ResNet50(include_top = False, weights = 'imagenet',\n","                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n","    conv_base.trainable=False\n","    model = conv_base.output\n","    model = layers.GlobalAveragePooling2D()(model)\n","    model = layers.Dense(1024, activation = 'relu')(model)\n","    model = layers.Dropout(0.3)(model)\n","    model = layers.Dense(512, activation = 'relu')(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(128, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(64, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(5, activation = \"softmax\")(model)\n","    model = models.Model(conv_base.input, model)\n","\n","    model.compile(optimizer = Adam(lr = 0.001),\n","                  loss = \"sparse_categorical_crossentropy\",\n","                  metrics = [\"acc\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = create_model()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_save = ModelCheckpoint('./ResNet50_16_512_best_weights.h5', \n","                             save_best_only = True, \n","                             save_weights_only = True,\n","                             monitor = 'val_loss', \n","                             mode = 'min', verbose = 1)\n","early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n","                           patience = 5, mode = 'min', verbose = 1,\n","                           restore_best_weights = True)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n","                              patience = 2, min_delta = 0.001, \n","                              mode = 'min', verbose = 1)\n","\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    validation_data = validation_generator,\n","    validation_steps = VALIDATION_STEPS,\n","    callbacks = [model_save, early_stop, reduce_lr]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","sns.set_style(\"white\")\n","plt.suptitle('Train history', size = 15)\n","\n","ax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\n","ax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\n","ax1.set_title(\"Training and validation acc\")\n","ax1.legend()\n","\n","ax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\n","ax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\n","ax2.set_title(\"Training and validation loss\")\n","ax2.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# InceptionV3"]},{"cell_type":"markdown","metadata":{},"source":["1. 4 hidden layers : [1024,512,128,64]\n","2. used Dropout after each layer\n","3. Metrics used: Accuracy\n","4. EPOCHS = 3\n","5. TARGET_SIZE = 512\n","6. BATCH_SIZE = 16"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_model():\n","    conv_base = InceptionV3(include_top = False, weights = 'imagenet',\n","                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n","    conv_base.trainable=False\n","    model = conv_base.output\n","    model = layers.GlobalAveragePooling2D()(model)\n","    model = layers.Dense(1024, activation = 'relu')(model)\n","    model = layers.Dropout(0.3)(model)\n","    model = layers.Dense(512, activation = 'relu')(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(128, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(64, activation = \"relu\")(model)\n","    model = layers.Dropout(0.2)(model)\n","    model = layers.Dense(5, activation = \"softmax\")(model)\n","    model = models.Model(conv_base.input, model)\n","\n","    model.compile(optimizer = Adam(lr = 0.001),\n","                  loss = \"sparse_categorical_crossentropy\",\n","                  metrics = [\"acc\"])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = create_model()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_save = ModelCheckpoint('./InceptionV3_16_512_best_weights.h5', \n","                             save_best_only = True, \n","                             save_weights_only = True,\n","                             monitor = 'val_loss', \n","                             mode = 'min', verbose = 1)\n","early_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n","                           patience = 5, mode = 'min', verbose = 1,\n","                           restore_best_weights = True)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n","                              patience = 2, min_delta = 0.001, \n","                              mode = 'min', verbose = 1)\n","\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = STEPS_PER_EPOCH,\n","    epochs = EPOCHS,\n","    validation_data = validation_generator,\n","    validation_steps = VALIDATION_STEPS,\n","    callbacks = [model_save, early_stop, reduce_lr]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","sns.set_style(\"white\")\n","plt.suptitle('Train history', size = 15)\n","\n","ax1.plot(epochs, acc, \"bo\", label = \"Training acc\")\n","ax1.plot(epochs, val_acc, \"b\", label = \"Validation acc\")\n","ax1.set_title(\"Training and validation acc\")\n","ax1.legend()\n","\n","ax2.plot(epochs, loss, \"bo\", label = \"Training loss\", color = 'red')\n","ax2.plot(epochs, val_loss, \"b\", label = \"Validation loss\", color = 'red')\n","ax2.set_title(\"Training and validation loss\")\n","ax2.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# End "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
